{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old notebook, most has been moved/is obsolete.  \n",
    "Still has some code for the diverse beam search experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting bashlex grammar using file: /home/jaron/shared/internship-jaron/bashlint/grammar/grammar100.txt\n",
      "Bashlint grammar set up (148 utilities)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, PreTrainedModel\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.insert(0, module_path)\n",
    "\n",
    "from src.config import cfg\n",
    "from src.generate import predict_single, encode, predict_single_mod\n",
    "from src.dataset import get_validation_data\n",
    "import src.diverse_beam_search as mbs\n",
    "\n",
    "from onnxruntime import InferenceSession, SessionOptions, ExecutionMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"output/nl2bash/08-26_18:11:32\"\n",
    "model_name = \"gpt2-large\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "set_cfg(run)\n",
    "set_cfg('device', 'cuda')\n",
    "tokenizer = get_tokenizer()\n",
    "model = get_model(tokenizer, resume=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(prompt):\n",
    "    return f\"{cfg('eos')} {cfg('sep1')} {prompt}\\n{cfg('sep2')}\"\n",
    "\n",
    "\n",
    "def decode(tokenizer, v):\n",
    "    text = tokenizer.decode(v, clean_up_tokenization_spaces=False)\n",
    "    # remove query at the start\n",
    "    start = text.find(cfg('sep2')) + len(cfg('sep2'))\n",
    "    text = text[start:]\n",
    "    # remove possible junk at the end\n",
    "    end = text.find(\"\\n\")\n",
    "    if end!=-1:\n",
    "        text = text[:end]\n",
    "    text = text.strip('\\n ')\n",
    "    return text\n",
    "\n",
    "\n",
    "def decode_batch(tokenizer, vs):\n",
    "    return [decode(tokenizer, v) for v in vs]\n",
    "\n",
    "def tokenize_query(tokenizer, prompt):\n",
    "    prompt = encode(prompt)\n",
    "    encoded_prompt = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    return encoded_prompt.to(device)\n",
    "\n",
    "\n",
    "def predict_single_div(model, tokenizer, prompt, top=1, max_length=None, beams=None):\n",
    "    prompt = tokenize_query(tokenizer, prompt)\n",
    "    \n",
    "    PreTrainedModel._generate_beam_search = mbs._generate_beam_search\n",
    "    output = model.generate(\n",
    "        input_ids=prompt,\n",
    "        max_length=200,\n",
    "        num_beams=beams,\n",
    "        do_sample=False,\n",
    "        num_return_sequences=top,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        #fp16 = True\n",
    "        )\n",
    "    output = decode_batch(tokenizer, output)\n",
    "    if len(output) == 1:\n",
    "        return output[0]\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.diverse_beam_search' from '/home/jaron/shared/internship-jaron/src/diverse_beam_search.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIVERSE BEAM SEARCH 2\n",
      "RESULTS\n",
      "find Path -size +Size -print0 | xargs -0 -I {} grep -l -H Regex {}\n",
      "find Path -size +Size -name Regex -print\n",
      "find Path -iname Regex -size +Size\n",
      "find Path -size +Size -print | xargs -I {} grep -l Regex {}\n",
      "find Path $(find Path -size +Size) -type f -size +Size\n",
      "CPU times: user 5.38 s, sys: 22.9 ms, total: 5.41 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = 'search all pdf files large than 10GB in the current folder'\n",
    "q = predict_single_div(model, tokenizer, prompt, beams=5, top=5)\n",
    "\n",
    "print(\"RESULTS\")\n",
    "for cm in q:\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "find Path -size +Size -iname Regex\n",
      "find Path -size +Size -iname Regex -print\n",
      "find Path -size +Size -print0 | xargs -0 -I {} grep -H -n Regex {}\n",
      "find Path -size +Size -name Regex -print\n",
      "find Path -type f -size +Size -print0 | xargs -0 -I {} grep -H -n Regex {}\n",
      "CPU times: user 460 ms, sys: 36.1 ms, total: 496 ms\n",
      "Wall time: 494 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = 'search all pdf files large than 10GB in the current folder\"'\n",
    "q = predict_single_mod(model, tokenizer, query, beams=5, top=5)\n",
    "print(\"RESULTS\")\n",
    "for cm in q[0]:\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template_score(dev_cm, pred_cms, confs):\n",
    "    PARAMS = {'u1': 1., 'u2':1.}\n",
    "    scores = [compute_metric(pred_cm, conf, dev_cm, PARAMS)\n",
    "                for pred_cm, conf in zip(pred_cms, confs)]\n",
    "\n",
    "    if any(x > 0 for x in scores):\n",
    "        total_score = max(scores)\n",
    "    else:\n",
    "        total_score = sum(scores) / len(scores)\n",
    "    return total_score\n",
    "\n",
    "def validate(model, tokenizer, dev_nls, dev_cms, overconfident=False, zero_hack=False):\n",
    "    outputs = [predict_single_mod(model, tokenizer, dev_nl, top=cfg('val_n')) \n",
    "                for dev_nl in dev_nls]\n",
    "    \n",
    "    confidences = [x[1] for x in outputs]\n",
    "    predictions = [x[0] for x in outputs]\n",
    "    \n",
    "    if overconfident:\n",
    "        confidences = [[1. for _ in entry] for entry in confidences]\n",
    "    \n",
    "    if zero_hack:\n",
    "        for entry in confidences:\n",
    "            entry[-1] = 0\n",
    "\n",
    "    scores_template = [get_template_score(dev_cm[0], pred_cm, confs) \n",
    "                for (pred_cm, confs, dev_cm) in zip(predictions, confidences, dev_cms)]\n",
    "    print(f\"[DEBUG]: TM score {np.mean(scores_template)}\")\n",
    "\n",
    "    scores_blue = [sentence_bleu(dev_cm, pred_cm[0]) \n",
    "                for (pred_cm, dev_cm) in zip(predictions, dev_cms)]\n",
    "    print(f\"[DEBUG]: BLUE score {np.mean(scores_blue)}\")\n",
    "\n",
    "    if cfg('val_metric') == 'BLUE':\n",
    "        scores = scores_blue\n",
    "    elif cfg('val_metric') == 'template':\n",
    "        scores = scores_template\n",
    "    else:\n",
    "        assert False, f\"Unkown validation metric '{metric}'\"\n",
    "    return scores, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/nl2bash/dev_cm.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/shared/internship-jaron/src/dataset.py\u001b[0m in \u001b[0;36mget_validation_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mdev_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'devsm_cm.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mdev_nl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'devsm_nl.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shared/internship-jaron/src/data_utils.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/nl2bash/devsm_cm.txt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e10fc6a5ccc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_nls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_cms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_validation_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/shared/internship-jaron/src/dataset.py\u001b[0m in \u001b[0;36mget_validation_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdev_nl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'devsm_nl.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mdev_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev_cm.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mdev_nl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dev_nl.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shared/internship-jaron/src/data_utils.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/nl2bash/dev_cm.txt'"
     ]
    }
   ],
   "source": [
    "dev_nls, dev_cms = get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
